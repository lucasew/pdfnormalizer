#!/usr/bin/env nix-shell
#! nix-shell -i python -p python3Packages.pdf2image python3Packages.pysimplegui python3Packages.opencv4 python3Packages.screeninfo python3Packages.tensorflow python3Packages.keras python3Packages.matplotlib python3Packages.pytesseract python3Packages.tqdm
# vim:ft=python

from argparse import ArgumentParser
from pdf2image import convert_from_path
from pathlib import Path
from io import BytesIO
import PySimpleGUI as sg
import numpy as np
import cv2
import random
from screeninfo import get_monitors, Enumerator
from pdfnormalizer.utils import array_to_data, GUI, GUIHandler, log, Exporter, sigmoid_focal_crossentropy_loss
from pdfnormalizer.model import Element, prepare_page_for_subdivision, get_bounding_boxes, SubdivisionAction, trim_whitespace
import tensorflow as tf
from PIL import Image
from tqdm import tqdm

from matplotlib import pyplot as plt

from pytesseract import image_to_string

parser = ArgumentParser()
parser.add_argument('-i', type=Path, help="PDF file to process", required=True)
parser.add_argument('-z', type=float, help="zoom scale", default=1)
parser.add_argument('-n', type=int, help="start at page", default=1)
parser.add_argument('-m', type=Path, help="model file (h5)", required=True)

args = parser.parse_args()

scale = args.z

images = convert_from_path(args.i)
qt_images = len(images)

model = tf.keras.models.load_model(args.m, custom_objects=dict(
    sigmoid_focal_crossentropy_loss=sigmoid_focal_crossentropy_loss
))

def predict_page(img):
    w, h, *rest = img.shape
    img = img.copy()
    prepared = prepare_page_for_subdivision(img)
    queue = []
    visited = {}
    queue.append((*trim_whitespace(prepared), 1))
    while len(queue) > 0:
        (x, y, sx, sy, depth) = queue.pop()
        # log(x, y, sx, sy, depth)
        if depth > 20:
            continue
        if (x, y, sx, sy) in visited:
            continue
        bbh = get_bounding_boxes(
            prepared,
            depth=depth,
            horizontal=True,
            sx=sx,
            sy=sy,
            x=x,
            y=y,
            max_depth=depth+1
        )
        bbv = get_bounding_boxes(
            prepared,
            depth=depth,
            horizontal=False,
            sx=sx,
            sy=sy,
            x=x,
            y=y,
            max_depth=depth+1
        )
        prediction = SubdivisionAction.END_THRASH
        if len(bbh) == 2 and len(bbv) == 2:
            cls = model.predict(np.array([[
                depth/20,
                x / w,
                y / h,
                sx / w,
                sy / h,
                bbh[0].sx/sx,
                bbv[0].sy/sy
            ]]))
            prediction = SubdivisionAction(int(tf.argmax(cls.T)[0])+1)
        if prediction == SubdivisionAction.HORIZONTAL:
            for it in bbh:
                queue.append([
                    int(it.x*w),
                    int(it.y*h),
                    int(it.sx*w),
                    int(it.sy*h),
                    depth+1
                ])
        if prediction == SubdivisionAction.VERTICAL:
            for it in bbv:
                queue.append([
                    int(it.x*w),
                    int(it.y*h),
                    int(it.sx*w),
                    int(it.sy*h),
                    depth+1
                ])
        if prediction == SubdivisionAction.END_TEXT:
            yield ('text', x, sx, y, sy, depth)
        if prediction == SubdivisionAction.END_FIGURE:
            yield ('figure', x, sx, y, sy, depth)
        if prediction == SubdivisionAction.END_THRASH:
            pass # ignore, as it is trash
        if prediction not in [SubdivisionAction.VERTICAL, SubdivisionAction.HORIZONTAL]:
            visited[x, y, sx, sy] = True

print(Exporter.pre())
for (i, image) in enumerate(tqdm(images)):
    image = np.array(image)
    # log(image)
    print(f"<!-- PÃ¡gina {i} -->")
    for (kind, x, sx, y, sy, depth) in predict_page(image):
        print(Exporter.block(image, kind, x, sx, y, sy, depth))
print(Exporter.pos())
