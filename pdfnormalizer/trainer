#!/usr/bin/env nix-shell
#! nix-shell -i python -p python3Packages.tensorflow python3Packages.keras python3Packages.pandas python3Packages.scikit-learn
# vim:ft=python

from argparse import ArgumentParser
from pathlib import Path
import sqlite3

import numpy as np
import pandas as pd
import tensorflow as tf
from matplotlib import pyplot as plt
from pdfnormalizer.model import SubdivisionAction
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix
from sklearn.metrics import classification_report

parser = ArgumentParser()
parser.add_argument("-d", type=Path, help="db file to input", required=True)
parser.add_argument("-e", type=int, help="epochs", default=200)
parser.add_argument("-m", type=bool, help="mostrar matriz de confusão", default=False)
parser.add_argument("-a", type=bool, help="mostrar loss e acurácia", default=False)
parser.add_argument("-o", type=Path, help="onde salvar o modelo")
args = parser.parse_args()

conn = sqlite3.connect(str(args.d))
df = pd.read_sql("select * from datapoints", con=conn)
print(df)

df['classification_idx'] = list(map(
    lambda v: SubdivisionAction[v.replace("SubdivisionAction.", "")].value - 1,
    df['classification']
))
labels = list(map(
    lambda v: SubdivisionAction[v.replace("SubdivisionAction.", "")].name,
    list(df['classification'].unique())
))

print("labels", labels)
df['norm_depth'] = df['depth'] / 20

NUM_CLASSES = len(labels)
print("classes", NUM_CLASSES)


def extract_datapoints(df):
    return df[['norm_depth', 'x', 'y', 'sx', 'sy']], df[['classification_idx']]


df_train = df.sample(frac=0.7, random_state=0)
df_test = df.drop(df_train.index)

x_train, y_train = extract_datapoints(df_train)
x_test, y_test = extract_datapoints(df_test)
# print(oh_classification)

print(df)

model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(5, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(8, activation='relu'),
    # classificação multiclasse
    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

history = model.fit(x_train, y_train, epochs=args.e)
print(model.evaluate(x_test, y_test))

if args.o is not None:
    model.save(str(args.o))

if args.a:
    plt.plot(history.epoch, history.history['accuracy'], 'r', label="Acurácia")
    plt.plot(history.epoch, history.history['loss'], 'g', label="Loss")
    plt.legend()
    plt.show()

if args.m:
    predicted = model.predict(x_test)
    y_test = np.array(y_test)
    norm_predicted = np.cast['int8'](tf.argmax(predicted.T))
    print(y_test.dtype, y_test.shape, predicted.dtype, predicted.shape, norm_predicted.shape, norm_predicted.dtype)

    print(classification_report(y_test, norm_predicted, labels=list(range(NUM_CLASSES)), target_names=labels))

    cm = confusion_matrix(y_test, norm_predicted, labels=list(range(NUM_CLASSES)))
    print(cm)
    ConfusionMatrixDisplay(
        cm,
        display_labels=labels
    ).plot()

    plt.show()
